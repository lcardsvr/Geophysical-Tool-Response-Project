{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries to use\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import itertools\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save CSV's as pandas DF variables\n",
    "tool_0028AA_df = pd.read_csv(\"Resources/Output_data/tool_0028AA_df.csv\")\n",
    "tool_9622C_df = pd.read_csv(\"Resources/Output_data/tool_9622C_df.csv\")\n",
    "# tool_xxx_df = pd.read_csv(\"Resources/xxx.csv\")\n",
    "# tool_xxx_df = pd.read_csv(\"Resources/xxx.csv\")\n",
    "# tool_xxx_df = pd.read_csv(\"Resources/xxx.csv\")\n",
    "# tool_xxx_df = pd.read_csv(\"Resources/xxx.csv\")\n",
    "# tool_xxx_df = pd.read_csv(\"Resources/xxx.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_9622C_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_9622C_df.head()\n",
    "# 'SUSCEP_CGS E-5' 'SANGB_DEG' 'TEMP_CPS' "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge or alter tables here\n",
    "# Join multiple tools on Well ID and Depth? or just Well ID?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "tool_9622C_cleaned_df = tool_9622C_df[['SUSCEP_CGS E-5', 'SANGB_DEG', 'TEMP_CPS']]\n",
    "tool_9622C_cleaned_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean nulls\n",
    "tool_9622C_data = tool_9622C_cleaned_df.replace(-999.25, pd.NA)\n",
    "tool_9622C_data.dropna(inplace=True)\n",
    "tool_9622C_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale Data\n",
    "scaler = StandardScaler()\n",
    "scaled_9622C_data = scaler.fit_transform(tool_9622C_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a a list to store inertia values and the values of k\n",
    "inertia = []\n",
    "k = list(range(1, 11)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a for-loop where each value of k is evaluated using the K-means algorithm\n",
    "# Fit the model using the service_ratings DataFrame\n",
    "# Append the value of the computed inertia from the `inertia_` attribute of the KMeans model instance\n",
    "for i in k:\n",
    "    k_model = KMeans(n_clusters=i, random_state=1)\n",
    "    k_model.fit(scaled_9622C_data)\n",
    "    inertia.append(k_model.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a DataFrame to hold the values for k and the corresponding inertia\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "\n",
    "# Review the DataFrame\n",
    "df_elbow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the DataFrame\n",
    "df_elbow.hvplot.line(\n",
    "    x=\"k\", \n",
    "    y=\"inertia\", \n",
    "    title=\"Elbow Curve\", \n",
    "    xticks=k\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose number of clusters\n",
    "model = KMeans(n_clusters=4)\n",
    "model.fit(scaled_9622C_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data_df = pd.DataFrame(scaled_9622C_data, columns = ['SUSCEP_CGS E-5', 'SANGB_DEG', 'TEMP_CPS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST \n",
    "# Fit the model\n",
    "model.fit(scaled_data_df)\n",
    "\n",
    "# Make predictions\n",
    "k_4 = model.predict(scaled_data_df)\n",
    "\n",
    "# Create a copy of the DataFrame\n",
    "tool_9622C_predictions_df = scaled_data_df.copy()\n",
    "\n",
    "# Add a class column with the labels\n",
    "tool_9622C_predictions_df['Cluster'] = k_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_9622C_predictions_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters\n",
    "tool_9622C_predictions_df.hvplot.scatter(\n",
    "    x=\"SUSCEP_CGS E-5\",\n",
    "    y=\"TEMP_CPS\",\n",
    "    by=\"Cluster\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "clusters = model.fit_predict(scaled_data_df.iloc[:, [1, 2]])  # Corrected indexing\n",
    "scaled_data_df['Cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty array to store the Mahalanobis distances\n",
    "mahalanobis_distances = np.zeros((len(scaled_data_df),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mahalanobis_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster_label in np.unique(clusters):\n",
    "    cluster_data = scaled_data_df.loc[clusters == cluster_label, [\"DENSITY_G/CC\", \"POR(DEN)_PERCENT\"]]  # Adjust the features accordingly\n",
    "    \n",
    "    # Fit the Elliptic Envelope on the cluster data\n",
    "    envelope = EllipticEnvelope()\n",
    "    envelope.fit(cluster_data)\n",
    "    \n",
    "    # Calculate the Mahalanobis distance for each data point in the cluster\n",
    "    cluster_distances = envelope.mahalanobis(cluster_data)\n",
    "    \n",
    "    # Assign the Mahalanobis distances to the corresponding indices in the mahalanobis_distances array\n",
    "    mahalanobis_distances[clusters == cluster_label] = cluster_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average Mahalanobis distance across all clusters\n",
    "scaled_data_df['Mahalanobis_Distance'] = mahalanobis_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a threshold to determine outliers\n",
    "threshold = 2.5  # Adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers based on the threshold\n",
    "scaled_data_df['Is_Outlier'] = scaled_data_df['Mahalanobis_Distance'] > threshold\n",
    "scaled_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot outliers with data to see if it is classifying properly\n",
    "scaled_data_df.hvplot.scatter(\n",
    "    x=\"DENSITY_G/CC\", \n",
    "    y=\"POR(DEN)_PERCENT\", \n",
    "    by=\"Cluster\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise model and anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummies if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detector = EllipticEnvelope(contamination=0.05)  # Adjust the contamination parameter as needed, 0.05 suggests 5% of data are outliers, can lower if needed\n",
    "outlier_detector.fit(scaled_data)\n",
    "outlier_labels = outlier_detector.predict(scaled_data)\n",
    "data['Anomaly'] = outlier_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCSVLogger(CSVLogger):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 5 == 0:\n",
    "            super().on_epoch_end(epoch, logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning Parameters\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh']\n",
    "hidden_nodes_layer1_values = [32, 64, 128]\n",
    "hidden_nodes_layer2_values = [16, 32, 64]\n",
    "optimizers = ['adam', 'rmsprop']\n",
    "losses = ['binary_crossentropy', 'mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_combinations = list(itertools.product(activation_functions, hidden_nodes_layer1_values, hidden_nodes_layer2_values, optimizers, losses))\n",
    "parameter_combinations[103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(activation, hidden_nodes_layer1, hidden_nodes_layer2, optimizer, loss):\n",
    "    nn = tf.keras.models.Sequential()\n",
    "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=activation))\n",
    "    nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=activation))\n",
    "    nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "    nn.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "    nn.fit(X_train_scaled, y_train, epochs=20, callbacks=[CustomCSVLogger('model_tuning_results.csv', append=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Activation', 'Hidden Nodes Layer 1', 'Hidden Nodes Layer 2', 'Optimizer', 'Loss'])\n",
    "for params in parameter_combinations:\n",
    "    activation, hidden_nodes_layer1, hidden_nodes_layer2, optimizer, loss = params\n",
    "    train_model(activation, hidden_nodes_layer1, hidden_nodes_layer2, optimizer, loss)\n",
    "    results_df = results_df.append({'Activation': activation,\n",
    "                                    'Hidden Nodes Layer 1': hidden_nodes_layer1,\n",
    "                                    'Hidden Nodes Layer 2': hidden_nodes_layer2,\n",
    "                                    'Optimizer': optimizer,\n",
    "                                    'Loss': loss}, ignore_index=True)\n",
    "    \n",
    "results_df.to_csv('model_parameters.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
